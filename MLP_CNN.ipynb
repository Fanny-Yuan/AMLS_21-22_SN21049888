{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is about brain tumor classification using two deep learning methods: MLP and CNN (ResNet50). Models are trained with multiclass labels, however, you can do both binary classification and multiclassification using this code.\n",
    "\n",
    "The code is structured as follows:\n",
    "1. Load packages\n",
    "2. Preprocess data\n",
    "3. Train and test MLP models\n",
    "4. Train and test ResNet50 models\n",
    "\n",
    "You can run part 1 and part 2 first, then run either part 3 or part 4 to train and test your own model.\n",
    "\n",
    "ATTENTION: This code is based on Windows. If you want to run it on Google Colab or other linux based servers, please change all '\\\\'  to '/'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load packages\n",
    "The model is built using tensorflow 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data\n",
    "This part includes:\n",
    "\n",
    "1. labels encoding\n",
    "2. train set and test set preparation\n",
    "3. the function used to choose predict labels\n",
    "4. the function used to convert multiclass labels to binary labels\n",
    "\n",
    "If you want to do multiclassification, just run 1-3, if you want to do binary classification, run all the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='.\\\\dataset\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "slabels=pd.read_csv(data_path+'label.csv')['label']\n",
    "labels=[]\n",
    "for s in slabels:\n",
    "    if s=='no_tumor':\n",
    "        labels.append(0)\n",
    "    elif s=='meningioma_tumor':\n",
    "        labels.append(1)\n",
    "    elif s=='glioma_tumor':\n",
    "        labels.append(2)\n",
    "    else:\n",
    "        labels.append(3)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose predict label\n",
    "def predict(predicts):\n",
    "    predict_labels=[]\n",
    "    for p in predicts:\n",
    "        p=np.argmax(p)\n",
    "        predict_labels.append(p)  \n",
    "    return np.array(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass to binary\n",
    "def multi_to_binary(labels):\n",
    "    binary=[]\n",
    "    for label in labels:\n",
    "        binary.append(0) if label=='no_tumor' else binary.append(1)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Train and test MLP models\n",
    "Through part you can:\n",
    "\n",
    "1. prepare trainset and testset\n",
    "2. load my trained MLP model\n",
    "3. train your own MLP model\n",
    "4. test the model for multiclass and binary tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image processing\n",
    "names=pd.read_csv(data_path+'label.csv')['file_name']\n",
    "imgs=[]\n",
    "for name in names:\n",
    "    img=cv2.imread(data_path+'image\\\\'+name,cv2.IMREAD_GRAYSCALE)\n",
    "    imgs.append(np.array(img))\n",
    "imgs=np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split trainset and testset\n",
    "train_examples,test_examples,train_labels,test_labels=train_test_split(imgs,labels,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model\n",
    "mlp=tf.keras.models.load_model('.\\\\models\\\\mlp.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train your own MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[512, 512]),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "             optimizer = \"adam\", \n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples\n",
      "Epoch 1/20\n",
      "2400/2400 [==============================] - 67s 28ms/sample - loss: 4328.8874 - accuracy: 0.4304\n",
      "Epoch 2/20\n",
      "2400/2400 [==============================] - 62s 26ms/sample - loss: 804.7284 - accuracy: 0.5558\n",
      "Epoch 3/20\n",
      "2400/2400 [==============================] - 67s 28ms/sample - loss: 457.4655 - accuracy: 0.6208\n",
      "Epoch 4/20\n",
      "2400/2400 [==============================] - 66s 27ms/sample - loss: 202.2375 - accuracy: 0.7387\n",
      "Epoch 5/20\n",
      "2400/2400 [==============================] - 61s 25ms/sample - loss: 179.6432 - accuracy: 0.7275\n",
      "Epoch 6/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 129.7456 - accuracy: 0.7487\n",
      "Epoch 7/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 103.7183 - accuracy: 0.7796\n",
      "Epoch 8/20\n",
      "2400/2400 [==============================] - 60s 25ms/sample - loss: 62.0880 - accuracy: 0.8188\n",
      "Epoch 9/20\n",
      "2400/2400 [==============================] - 60s 25ms/sample - loss: 72.0776 - accuracy: 0.7954\n",
      "Epoch 10/20\n",
      "2400/2400 [==============================] - 60s 25ms/sample - loss: 34.1917 - accuracy: 0.8642\n",
      "Epoch 11/20\n",
      "2400/2400 [==============================] - 59s 24ms/sample - loss: 36.6240 - accuracy: 0.8450\n",
      "Epoch 12/20\n",
      "2400/2400 [==============================] - 59s 24ms/sample - loss: 26.0112 - accuracy: 0.8779\n",
      "Epoch 13/20\n",
      "2400/2400 [==============================] - 60s 25ms/sample - loss: 15.6669 - accuracy: 0.8954\n",
      "Epoch 14/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 28.4578 - accuracy: 0.8696\n",
      "Epoch 15/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 30.8244 - accuracy: 0.8592\n",
      "Epoch 16/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 73.5685 - accuracy: 0.7792\n",
      "Epoch 17/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 78.4266 - accuracy: 0.7775\n",
      "Epoch 18/20\n",
      "2400/2400 [==============================] - 59s 25ms/sample - loss: 33.2825 - accuracy: 0.8629\n",
      "Epoch 19/20\n",
      "2400/2400 [==============================] - 60s 25ms/sample - loss: 17.4750 - accuracy: 0.8929\n",
      "Epoch 20/20\n",
      "2400/2400 [==============================] - 60s 25ms/sample - loss: 18.7371 - accuracy: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2952e598d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(train_examples, train_labels,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "predicts=mlp.predict(test_examples)\n",
    "predict_labels=predict(predicts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7716666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiclass accuracy\n",
    "score=metrics.accuracy_score(test_labels,predict_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#binary accuracy\n",
    "predict_binary=multi_to_binary(predict_labels)\n",
    "test_binary=multi_to_binary(test_labels)\n",
    "score_binary=metrics.accuracy_score(test_binary,predict_binary)\n",
    "score_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Train and test ResNet50 models\n",
    "Through part you can:\n",
    "\n",
    "1. prepare trainset and testset\n",
    "2. load my trained ResNet50 model\n",
    "3. train your own ResNet model\n",
    "4. test the model for multiclass and binary tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prepare trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image processing\n",
    "names=pd.read_csv(data_path+'label.csv')['file_name']\n",
    "imgs=[]\n",
    "for name in names:\n",
    "    img=cv2.imread(data_path+'image\\\\'+name)\n",
    "    img=cv2.resize(img,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "    imgs.append(np.array(img))\n",
    "imgs=np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split trainset and testset\n",
    "train_examples,test_examples,train_labels,test_labels=train_test_split(imgs,labels,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=tf.keras.models.load_model('.\\\\models\\\\ResNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train your own ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "             optimizer = \"adam\", \n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.fit(train_examples, train_labels,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "predicts=res.predict(test_examples)\n",
    "predict_labels=predict(predicts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiclass accuracy\n",
    "score=metrics.accuracy_score(test_labels,predict_labels)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#binary accuracy\n",
    "predict_binary=multi_to_binary(predict_labels)\n",
    "test_binary=multi_to_binary(test_labels)\n",
    "score_binary=metrics.accuracy_score(test_binary,predict_binary)\n",
    "score_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
